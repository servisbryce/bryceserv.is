2:I[8047,["665","static/chunks/f97e080b-42dcf4837ed6a86e.js","240","static/chunks/53c13509-59dce8ec7d519f72.js","212","static/chunks/59650de3-fde12c1ab0f67ea8.js","516","static/chunks/f7333993-771a495057fa5276.js","452","static/chunks/5e22fd23-52eff41f1e309e93.js","464","static/chunks/464-5b46459779776405.js","7","static/chunks/7-b772be0ca217ec58.js","931","static/chunks/app/page-bd5dc6c2ebf0b037.js"],"Column"]
3:I[435,["665","static/chunks/f97e080b-42dcf4837ed6a86e.js","240","static/chunks/53c13509-59dce8ec7d519f72.js","212","static/chunks/59650de3-fde12c1ab0f67ea8.js","516","static/chunks/f7333993-771a495057fa5276.js","452","static/chunks/5e22fd23-52eff41f1e309e93.js","464","static/chunks/464-5b46459779776405.js","7","static/chunks/7-b772be0ca217ec58.js","931","static/chunks/app/page-bd5dc6c2ebf0b037.js"],"RevealFx"]
4:I[9316,["665","static/chunks/f97e080b-42dcf4837ed6a86e.js","240","static/chunks/53c13509-59dce8ec7d519f72.js","212","static/chunks/59650de3-fde12c1ab0f67ea8.js","516","static/chunks/f7333993-771a495057fa5276.js","452","static/chunks/5e22fd23-52eff41f1e309e93.js","464","static/chunks/464-5b46459779776405.js","7","static/chunks/7-b772be0ca217ec58.js","931","static/chunks/app/page-bd5dc6c2ebf0b037.js"],"Heading"]
5:I[2060,["665","static/chunks/f97e080b-42dcf4837ed6a86e.js","240","static/chunks/53c13509-59dce8ec7d519f72.js","212","static/chunks/59650de3-fde12c1ab0f67ea8.js","516","static/chunks/f7333993-771a495057fa5276.js","452","static/chunks/5e22fd23-52eff41f1e309e93.js","464","static/chunks/464-5b46459779776405.js","7","static/chunks/7-b772be0ca217ec58.js","931","static/chunks/app/page-bd5dc6c2ebf0b037.js"],"Text"]
6:I[2092,["665","static/chunks/f97e080b-42dcf4837ed6a86e.js","240","static/chunks/53c13509-59dce8ec7d519f72.js","212","static/chunks/59650de3-fde12c1ab0f67ea8.js","516","static/chunks/f7333993-771a495057fa5276.js","452","static/chunks/5e22fd23-52eff41f1e309e93.js","464","static/chunks/464-5b46459779776405.js","7","static/chunks/7-b772be0ca217ec58.js","931","static/chunks/app/page-bd5dc6c2ebf0b037.js"],"Button"]
7:I[1162,["665","static/chunks/f97e080b-42dcf4837ed6a86e.js","240","static/chunks/53c13509-59dce8ec7d519f72.js","212","static/chunks/59650de3-fde12c1ab0f67ea8.js","516","static/chunks/f7333993-771a495057fa5276.js","452","static/chunks/5e22fd23-52eff41f1e309e93.js","464","static/chunks/464-5b46459779776405.js","7","static/chunks/7-b772be0ca217ec58.js","931","static/chunks/app/page-bd5dc6c2ebf0b037.js"],"Flex"]
8:I[5312,["665","static/chunks/f97e080b-42dcf4837ed6a86e.js","240","static/chunks/53c13509-59dce8ec7d519f72.js","212","static/chunks/59650de3-fde12c1ab0f67ea8.js","516","static/chunks/f7333993-771a495057fa5276.js","452","static/chunks/5e22fd23-52eff41f1e309e93.js","464","static/chunks/464-5b46459779776405.js","7","static/chunks/7-b772be0ca217ec58.js","931","static/chunks/app/page-bd5dc6c2ebf0b037.js"],"Avatar"]
9:I[9818,["665","static/chunks/f97e080b-42dcf4837ed6a86e.js","240","static/chunks/53c13509-59dce8ec7d519f72.js","212","static/chunks/59650de3-fde12c1ab0f67ea8.js","516","static/chunks/f7333993-771a495057fa5276.js","452","static/chunks/5e22fd23-52eff41f1e309e93.js","464","static/chunks/464-5b46459779776405.js","7","static/chunks/7-b772be0ca217ec58.js","931","static/chunks/app/page-bd5dc6c2ebf0b037.js"],"ProjectCard"]
b:I[5094,["665","static/chunks/f97e080b-42dcf4837ed6a86e.js","240","static/chunks/53c13509-59dce8ec7d519f72.js","212","static/chunks/59650de3-fde12c1ab0f67ea8.js","516","static/chunks/f7333993-771a495057fa5276.js","452","static/chunks/5e22fd23-52eff41f1e309e93.js","464","static/chunks/464-5b46459779776405.js","7","static/chunks/7-b772be0ca217ec58.js","931","static/chunks/app/page-bd5dc6c2ebf0b037.js"],"Grid"]
c:I[7659,["665","static/chunks/f97e080b-42dcf4837ed6a86e.js","240","static/chunks/53c13509-59dce8ec7d519f72.js","212","static/chunks/59650de3-fde12c1ab0f67ea8.js","516","static/chunks/f7333993-771a495057fa5276.js","452","static/chunks/5e22fd23-52eff41f1e309e93.js","464","static/chunks/464-5b46459779776405.js","7","static/chunks/7-b772be0ca217ec58.js","931","static/chunks/app/page-bd5dc6c2ebf0b037.js"],"default"]
a:T85b,
# Why should I bother using a socket library?
A socket library reduces your program's design complexity, allowing you to focus on what's important instead of writing mostly boilerplate socket code. Furthermore, writing and implementing your socket code is complex and intensive, leaving plenty of room for error or security risks.

Furthermore, you must also implement Transport Layer Security overtop of your application, doubling the complexity as now you must rewrite your code for OpenSSL.

## What makes your socket library different?
My socket library is application layer and topology agnostic, meaning that you can opt to use encryption or avoid it entirely. You may also implement this socket library from a client or server perspective. You only have to configure the socket context to your liking, and then you may write your code once and have it work on both unencrypted traffic and encrypted traffic.

Furthermore, my socket library abstracts the process of creating contexts, binding to sockets, or reading and writing from said sockets. It's as simple and as streamlined as I could make it without encroaching on the developer experience.

# The developer experience.
My socket library is highly robust and accessible. To start, create a socket context: you'll need the address you'll be binding to or connecting to, along with the port, and whether you will be acting as a server or a client. But wait, what if you want to add Transport Layer Security? Use the create Transport Layer Security function and plug in your socket context, certificate, and private key files, and you're ready to go; you don't even have to rewrite your old socket code for unencrypted traffic handling as it automatically adjusts to the new changes that you've made with the context.

# My plans for the future.
I plan on eventually implementing keepalives and concurrent socket handling through whatever avenue is the most performant and accessible. I will likely assign user-defined functions to run whenever a new socket is accepted on the server side. A user-defined function will run in just one thread over one socket on the client side.d:T1189,
# What is a dynamic thread pool compared to a static thread pool?
A static thread pool is an effective and flexible way to parallelize any task. It has an unchanging number of threads in a structure called a pool. A program may assign functions to these pools, and a thread will elect to compute an assigned function.

On the contrary, a dynamic thread pool follows the same notion, except the number of threads in the pool may contract or expand depending on the program's priorities and preferences. A dynamic thread pool is significantly more scalable than a static one because if it becomes overloaded with tasks, it may request more threads to accommodate the increased load and then kill these threads when the load eventually decreases.

# When should a dynamic thread pool be used?
A dynamic thread pool should be used whenever the workload is unpredictable. Unpredictable workloads are typical in many types of applications, especially in applications that serve requests (servers). The ability for a thread pool to scale dynamically to accommodate an elevated but unanticipated demand is a much-preferred alternative to outright denying requests. However, there must be limits to prevent the dynamic thread pool from endlessly scaling itself up until it starts to overload the underlying operating system it's running on. Furthermore, the dynamic thread pool must also know when it's appropriate to scale down to prevent an excess of threads from accumulating that aren't going to be used.

# What algorithms determine when to scale a dynamic thread pool?
The stepwise scheduling algorithm is a standard method for determining when and how to scale dynamic thread pools. The stepwise scheduler is a straightforward yet effective way to scale the dynamic thread pool based on existing usage data without involving complex analysis. You must set a baseline thread target, regularly telling the algorithm the number of threads it wants in the pool whenever possible. Then, you must place a maximum for how many threads may be in the dynamic thread pool. Otherwise, you risk the dynamic thread pool from scaling up too much and taking down the entire operating system. The dynamic pool may not scale more than the maximum thread target. Finally, you must set a stepwise thread amount that tells the dynamic thread pool how much it should expand whenever it is at maximum load; the stepwise thread amount should be about 10% of the thread target and remain constant. However, your needs may change depending on your application.

The stepwise scheduling algorithm assumes that whenever the thread pool is overloaded, instead of expanding the pool by the minimum amount necessary to accommodate the demand at that moment, it should overallocate the number of threads to accommodate for an increased trend in demand over a prolonged period. Stepwise scheduling is helpful for applications such as servers that often experience protracted periods of unanticipated traffic.

# What are the tradeoffs for using a dynamic thread pool rather than a static thread pool?
A static thread pool never has to worry about the performance impact of creating or killing threads, as it only has to make them once. However, when overloaded, a static thread pool is forced to deny requests rather than serve them, which leads to unreliability in your application during exceptionally high loads.

Furthermore, suppose the dynamic thread pool is misconfigured. In that case, it may expand too aggressively and lead to system instability, resulting in requests being denied or the program outright crashing due to it starving from a lack of resources.

However, a properly configured and supervised dynamic thread pool is a scalable alternative to outright denying requests and disrupting others. It's a much more favorable alternative to scale up temporarily to accommodate prolonged bursts in traffic than to turn away empty-handed users.

Dynamic thread pools should not be used for applications with a constant or predictable workload, such as payroll or file backup systems. However, applications that have an unpredictable workload, such as web servers or streaming platforms. The dynamic thread pool must be configured to accommodate the balancing act between stability and raw processing power. If balanced improperly, the dynamic thread pool may cause the application to become unstable and prone to crashing. However, balancing this tradeoff is easy using the abovementioned stepwise algorithm.e:T907,
# Should I trust code generated by artificial intelligence?
Absolutely not, because artificial intelligence doesn't have the reasoning capabilities that you do. On numerous occasions, when I've experimented with artificial intelligence to see its programming capabilities, it often shipped broken, nonsensical code full of vulnerabilities and depreciated functions. You should treat all code generated by artificial intelligence as untrusted and unsafe.

You should always avoid copying code from artificial intelligence and throwing it directly into your program unless you're certain precisely what it's doing and why it's there.

# What should I use artificial intelligence for?
Artificial intelligence is exemplary at finding and recognizing patterns in data. This trait makes it incredibly good for debugging programs because it can match debugging data with its immense dataset and determine what might have happened. For example, I once encountered an extremely vague OpenSSL error, and there weren't any results on Google for it, so I couldn't figure it out and was stumped. However, when I asked artificial intelligence what the error may be caused, it provided an excellent synopsis that cleared up the vague error message and allowed me to patch the bug.

# What shouldn't I use artificial intelligence for?
Do not use artificial intelligence mindlessly. You must understand precisely what it's doing and saying because artificial intelligence cannot tell if it's saying is correct or not. Even though artificial intelligence is trained on massive datasets, you are still more intelligent than it because you can discern what is proper and what is false. You shouldn't use artificial intelligence for tasks you don't understand yourself. Instead, you should teach yourself the topic and learn it, then use artificial intelligence later as an assistant and not an expert. You should become an expert and use artificial intelligence to automate tasks that waste your time, then audit what the artificial intelligence outputs and make corrections.

In short, you shouldn't rely on artificial intelligence to be an expert for you; instead, you should use it like an assistant. You should become the expert and audit, modify, and adjust whatever outputs are spewed from the artificial intelligence model.f:Tc5b,
# What is the purpose of a memory allocator?
A memory allocator traditionally refers to a library that abstracts the process of heap management to a program. A program uses a memory allocator to allocate a specific number of bytes from the kernel to store data it needs later.

The program expects that the pointer to the segment of memory will never change unless requested by the program to do so.

## What's a heap, and what's a segment?
The heap is a pile of segments that grows upward toward the stack. It is composed of any integer multiple of the size of a page, typically 4 kilobytes.

On most architectures, the minimum page size is 4 kilobytes and can't be smaller or larger. The kernel lends programs to these pages whenever they need to store data in memory.

You may allocate a page of any size from the Linux kernel, but you'll run into significant performance and fragmentation issues at the kernel level sooner or later. So, only allocate integer multiples of the page size from the kernel.

A segment is just a slice of the heap that a program allocates to store data. It may be any number of bytes and isn't restricted to being an integer multiple of the page size.

# How is your memory allocator different?
Traditionally, many applications on Linux-based operating systems use the ```glibc malloc```, which has prided itself on being balanced in performance and efficiency. However, the ```glibc malloc``` codebase is complicated and immense, making it difficult for some to learn how a memory allocator is implemented in C.

My memory allocator was designed by a novice C programmer to be performant, efficient, and comprehensible. Its entire structure, including comments, is contained in 622 lines of code.

## Lazy operations.
My memory allocator uses lazy operations. These operations are reserved for computationally expensive functions that don't necessarily need to be run constantly. They've been delegated to run only when the counter that holds the number of calls to the operation has reached a certain threshold. Upon reaching this threshold, the operation executes, and the counter for the number of calls is subtracted by one.

These lazy operations significantly reduce latency on the majority of operations. However, if the thresholds for these lazy operations aren't balanced correctly, they may lead to more program memory usage.

## No arenas or binning.
Furthermore, my memory allocator doesn't use arenas or bins, which are common in many memory allocators. Arenas or bins work by processing and sorting free segments based on their sizes, then picking one and providing it to the program. However, arenas and bins add significant design complexity, so I've excluded them entirely from my memory allocator implementation.

# Is this production ready?
No, this memory allocator wasn't designed for production. Although I've ensured that it remains stable under various standard conditions, I'm sure that it is not as hardened or battle-tested as ```glibc malloc```.

This memory allocator is a learning tool that demonstrates what a simple yet fast and efficient memory allocator in the C programming language looks like.10:T8f5,
# What's your design criteria?
I wanted a personal website that could act as my blog, project portfolio, and biography and be flexible to customize and expand later.

I didn't want to reinvent the wheel either, and I didn't want to spend days getting my site up and running. Therefore, I needed to use an excellent template and fork it to customize it.

# What framework did you use?
At first, I wanted to use Nuxt. Still, I encountered considerable issues that made the development experience painful and slowâ€”from my personal experience, trying to use design systems like Preline was like pulling teeth.

Eventually, I landed on Nuxt's neighbor, Next.js, and I immediately fell in love with its simplicity, superb developer experience, and broad support. Furthermore, Next.js was natively supported by Vercel which made deploying my application a breeze.

# What template did you use?
Once I had decided on the framework I'd be using; I needed to find a flexible template that didn't require me to reinvent the wheel. 

After browsing GitHub, I landed on Magic Portfolio powered by Once UI. The design of Magic Portfolio was perfect, simple, and easy to modify to my liking.

# What do you plan on implementing in your fork?
I immediately got to work and forked Magic Portfolio. I made several changes, such as renaming tabs to make them more appropriate, trimming down some parts I didn't need, like password-protected routes, and writing a few project posts (including the one you're reading right now).

I plan to implement significant additions to modify the website's design and style. Specifically, I wish to alter the navigation bar to make it larger and a glassy blur. I also want to write more project posts on GitHub for all my finished projects.

# What did you use to deploy your website?
Vercel made deploying my website a dream. Previously, I used a virtual private server to host my applications; however, it was clunky and generally slower than I wanted.

Thankfully, Vercel exists. Vercel is a fantastic platform that allows you to deploy your application almost straight from your GitHub account. Push to central, and Vercel will take care of the rest by building and deploying your web application.

I also migrated over from Cloudflare to Vercel for my proxy solution.0:["I1qaTd-5GaVEFbffRg-zN",[[["",{"children":["__PAGE__",{}]},"$undefined","$undefined",true],["",{"children":["__PAGE__",{},[["$L1",["$","$L2",null,{"maxWidth":"m","gap":"xl","horizontal":"center","children":[["$","script",null,{"type":"application/ld+json","suppressHydrationWarning":true,"dangerouslySetInnerHTML":{"__html":"{\"@context\":\"https://schema.org\",\"@type\":\"WebPage\",\"name\":\"Bryce Servis's Portfolio\",\"description\":\"Portfolio website showcasing my projects as a Hobbyist Programmer\",\"url\":\"https://bryceserv.is\",\"image\":\"bryceserv.is/og?title=Bryce%20Servis's%20Portfolio\",\"publisher\":{\"@type\":\"Person\",\"name\":\"Bryce Servis\",\"image\":{\"@type\":\"ImageObject\",\"url\":\"bryceserv.is/images/avatar.png\"}}}"}}],["$","$L2",null,{"fillWidth":true,"paddingY":"l","gap":"m","children":["$","$L2",null,{"maxWidth":"s","children":[["$","$L3",null,{"translateY":"4","fillWidth":true,"horizontal":"start","paddingBottom":"m","children":["$","$L4",null,{"wrap":"balance","variant":"display-strong-l","children":["Hello, ",["$","br",null,{}],"I'm Bryce."]}]}],["$","$L3",null,{"translateY":"8","delay":0.2,"fillWidth":true,"horizontal":"start","paddingBottom":"m","children":["$","$L5",null,{"wrap":"balance","onBackground":"neutral-weak","variant":"heading-default-xl","children":"I am a hobbyist programmer and a student. I develop applications and libraries for Linux-based operating systems. But I also love tinkering and learning new technologies and languages to grow my skills as a programmer."}]}],["$","$L3",null,{"translateY":"12","delay":0.4,"horizontal":"start","children":["$","$L6",null,{"id":"about","data-border":"rounded","href":"/about","variant":"secondary","size":"m","arrowIcon":true,"children":["$","$L7",null,{"gap":"8","vertical":"center","children":[["$","$L8",null,{"style":{"marginLeft":"-0.75rem","marginRight":"0.25rem"},"src":"/images/avatar.png","size":"m"}],"About me"]}]}]}]]}]}],["$","$L3",null,{"translateY":"16","delay":0.6,"children":["$","$L2",null,{"fillWidth":true,"gap":"xl","marginBottom":"40","paddingX":"l","children":[["$","$L9","libsocket",{"priority":true,"href":"/projects/libsocket","images":["/images/gallery/libsocket.png"],"title":"libsocket","description":"An application layer agnostic socket library designed for portability and performance.","content":"$a","avatars":[{"src":"/images/avatar.png"}],"link":"https://github.com/servisbryce/libsocket"}]]}]}],["$","$L7",null,{"fillWidth":true,"gap":"24","mobileDirection":"column","children":[["$","$L7",null,{"flex":1,"paddingLeft":"l","children":["$","$L4",null,{"as":"h2","variant":"display-strong-xs","wrap":"balance","children":"Latest from the blog"}]}],["$","$L7",null,{"flex":3,"paddingX":"20","children":["$","$Lb",null,{"columns":"2","mobileColumns":"1","fillWidth":true,"marginBottom":"40","gap":"m","children":[["$","$Lc","thecasefordynamicthreadpools",{"post":{"metadata":{"title":"The Case for Dynamic Thread Pools","publishedAt":"2025-04-06","summary":"The reasons why you should consider using dynamic thread pools in your applications.","image":"/images/gallery/thecasefordynamicthreadpools.jpg","images":[],"tag":"Journal","team":[],"link":""},"slug":"thecasefordynamicthreadpools","content":"$d"},"thumbnail":false}],["$","$Lc","whenshouldyouleverageartificalintelligence",{"post":{"metadata":{"title":"When Should You Leverage Artifical Intelligence in Programming?","publishedAt":"2025-04-03","summary":"The playbook on when to use artifical intelligence when programming.","image":"/images/gallery/whenshouldyouleverageartificalintelligence.jpg","images":[],"tag":"Journal","team":[],"link":""},"slug":"whenshouldyouleverageartificalintelligence","content":"$e"},"thumbnail":false}]]}]}]]}],["$","$L2",null,{"fillWidth":true,"gap":"xl","marginBottom":"40","paddingX":"l","children":[["$","$L9","malloc",{"priority":true,"href":"/projects/malloc","images":["/images/gallery/malloc.jpg"],"title":"malloc","description":"A brief dive into the inner workings of heap allocators in the C programming language.","content":"$f","avatars":[{"src":"/images/avatar.png"}],"link":"https://github.com/servisbryce/malloc"}],["$","$L9","bryceserv.is",{"priority":true,"href":"/projects/bryceserv.is","images":["/images/gallery/bryceserv.is.png"],"title":"bryceserv.is","description":"My personal website and portfolio.","content":"$10","avatars":[{"src":"/images/avatar.png"}],"link":"https://github.com/servisbryce/bryceserv.is"}]]}]]}],null],null],null]},[[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/15b9922eb12b1bb5.css","precedence":"next","crossOrigin":"$undefined"}],["$","link","1",{"rel":"stylesheet","href":"/_next/static/css/bf5abfa89ee118e0.css","precedence":"next","crossOrigin":"$undefined"}],["$","link","2",{"rel":"stylesheet","href":"/_next/static/css/a8c4e1ca9815a60e.css","precedence":"next","crossOrigin":"$undefined"}],["$","link","3",{"rel":"stylesheet","href":"/_next/static/css/e578cf952a0222b2.css","precedence":"next","crossOrigin":"$undefined"}]],"$L11"],null],null],["$L12",null]]]]
13:I[6995,["665","static/chunks/f97e080b-42dcf4837ed6a86e.js","240","static/chunks/53c13509-59dce8ec7d519f72.js","212","static/chunks/59650de3-fde12c1ab0f67ea8.js","516","static/chunks/f7333993-771a495057fa5276.js","452","static/chunks/5e22fd23-52eff41f1e309e93.js","464","static/chunks/464-5b46459779776405.js","7","static/chunks/7-b772be0ca217ec58.js","931","static/chunks/app/page-bd5dc6c2ebf0b037.js"],"ToastProvider"]
14:I[124,["665","static/chunks/f97e080b-42dcf4837ed6a86e.js","240","static/chunks/53c13509-59dce8ec7d519f72.js","212","static/chunks/59650de3-fde12c1ab0f67ea8.js","516","static/chunks/f7333993-771a495057fa5276.js","452","static/chunks/5e22fd23-52eff41f1e309e93.js","464","static/chunks/464-5b46459779776405.js","7","static/chunks/7-b772be0ca217ec58.js","931","static/chunks/app/page-bd5dc6c2ebf0b037.js"],"Background"]
15:I[9295,["665","static/chunks/f97e080b-42dcf4837ed6a86e.js","240","static/chunks/53c13509-59dce8ec7d519f72.js","212","static/chunks/59650de3-fde12c1ab0f67ea8.js","516","static/chunks/f7333993-771a495057fa5276.js","452","static/chunks/5e22fd23-52eff41f1e309e93.js","464","static/chunks/464-5b46459779776405.js","7","static/chunks/7-b772be0ca217ec58.js","931","static/chunks/app/page-bd5dc6c2ebf0b037.js"],"Header"]
16:I[9890,["665","static/chunks/f97e080b-42dcf4837ed6a86e.js","240","static/chunks/53c13509-59dce8ec7d519f72.js","212","static/chunks/59650de3-fde12c1ab0f67ea8.js","516","static/chunks/f7333993-771a495057fa5276.js","452","static/chunks/5e22fd23-52eff41f1e309e93.js","464","static/chunks/464-5b46459779776405.js","7","static/chunks/7-b772be0ca217ec58.js","931","static/chunks/app/page-bd5dc6c2ebf0b037.js"],"Route"]
17:I[4707,[],""]
18:I[6423,[],""]
19:I[7868,["665","static/chunks/f97e080b-42dcf4837ed6a86e.js","240","static/chunks/53c13509-59dce8ec7d519f72.js","212","static/chunks/59650de3-fde12c1ab0f67ea8.js","516","static/chunks/f7333993-771a495057fa5276.js","452","static/chunks/5e22fd23-52eff41f1e309e93.js","464","static/chunks/464-5b46459779776405.js","7","static/chunks/7-b772be0ca217ec58.js","931","static/chunks/app/page-bd5dc6c2ebf0b037.js"],"IconButton"]
11:["$","$L7",null,{"as":"html","lang":"en","background":"page","data-neutral":"slate","data-brand":"aqua","data-accent":"aqua","data-solid":"contrast","data-solid-style":"flat","data-theme":"dark","data-border":"conservative","data-surface":"translucent","data-transition":"all","className":"__variable_d65c78 __variable_bcf733","children":["$","$L13",null,{"children":["$","$L2",null,{"style":{"minHeight":"100vh"},"as":"body","fillWidth":true,"margin":"0","padding":"0","children":[["$","$L14",null,{"mask":{"cursor":false,"x":0,"y":0,"radius":75},"gradient":{"display":false,"x":50,"y":0,"width":100,"height":100,"tilt":0,"colorStart":"brand-background-strong","colorEnd":"static-transparent","opacity":50},"dots":{"display":false,"color":"brand-on-background-weak","size":1,"opacity":100},"grid":{"display":true,"color":"brand-background-strong","width":"$undefined","height":"$undefined","opacity":100},"lines":{"display":false,"opacity":100}}],["$","$L7",null,{"fillWidth":true,"minHeight":"16"}],["$","$L15",null,{}],["$","$L7",null,{"position":"relative","zIndex":0,"fillWidth":true,"paddingY":"l","paddingX":"l","horizontal":"center","flex":1,"children":["$","$L7",null,{"horizontal":"center","fillWidth":true,"minHeight":"0","children":["$","$L16",null,{"children":["$","$L17",null,{"parallelRouterKey":"children","segmentPath":["children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L18",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":["$","$L2",null,{"as":"section","fill":true,"center":true,"paddingBottom":"160","children":[["$","$L5",null,{"marginBottom":"s","variant":"display-strong-xl","children":"404"}],["$","$L4",null,{"marginBottom":"l","variant":"display-default-xs","children":"Page Not Found"}],["$","$L5",null,{"onBackground":"neutral-weak","children":"The page you are looking for does not exist."}]]}],"notFoundStyles":[]}]}]}]}],["$","$L7",null,{"as":"footer","position":"relative","fillWidth":true,"padding":"8","horizontal":"center","mobileDirection":"column","children":[["$","$L7",null,{"className":"Footer_mobile__TYNqJ","maxWidth":"m","paddingY":"8","paddingX":"16","gap":"16","horizontal":"space-between","vertical":"center","children":[["$","$L5",null,{"variant":"body-default-s","onBackground":"neutral-strong","children":"Published on April 2nd, 2025."}],["$","$L7",null,{"gap":"16","children":[["$","$L19","Email",{"href":"mailto:bryceservis@bryceserv.is","icon":"email","tooltip":"Email","size":"s","variant":"ghost"}],["$","$L19","Pretty Good Privacy",{"href":"/907873A1.asc","icon":"pgp","tooltip":"Pretty Good Privacy","size":"s","variant":"ghost"}],["$","$L19","Resume",{"href":"/resume.pdf","icon":"doc","tooltip":"Resume","size":"s","variant":"ghost"}],["$","$L19","GitHub",{"href":"https://github.com/servisbryce/","icon":"github","tooltip":"GitHub","size":"s","variant":"ghost"}],["$","$L19","LinkedIn",{"href":"https://www.linkedin.com/in/bryce-servis-328381357","icon":"linkedin","tooltip":"LinkedIn","size":"s","variant":"ghost"}]]}]]}],["$","$L7",null,{"height":"80","show":"s"}]]}]]}]}]}]
12:[["$","meta","0",{"name":"viewport","content":"width=device-width, initial-scale=1"}],["$","meta","1",{"charSet":"utf-8"}],["$","title","2",{"children":"Bryce Servis's Portfolio"}],["$","meta","3",{"name":"description","content":"Portfolio website showcasing my projects as a Hobbyist Programmer"}],["$","meta","4",{"name":"robots","content":"index, follow"}],["$","meta","5",{"name":"googlebot","content":"index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1"}],["$","meta","6",{"property":"og:title","content":"Bryce Servis's Portfolio"}],["$","meta","7",{"property":"og:description","content":"Portfolio website showcasing my projects as a Hobbyist Programmer"}],["$","meta","8",{"property":"og:url","content":"https://bryceserv.is/"}],["$","meta","9",{"property":"og:image","content":"https://bryceserv.is/og?title=Bryce%20Servis%27s%20Portfolio"}],["$","meta","10",{"property":"og:image:alt","content":"Bryce Servis's Portfolio"}],["$","meta","11",{"property":"og:type","content":"website"}],["$","meta","12",{"name":"twitter:card","content":"summary_large_image"}],["$","meta","13",{"name":"twitter:title","content":"Bryce Servis's Portfolio"}],["$","meta","14",{"name":"twitter:description","content":"Portfolio website showcasing my projects as a Hobbyist Programmer"}],["$","meta","15",{"name":"twitter:image","content":"https://bryceserv.is/og?title=Bryce%20Servis%27s%20Portfolio"}],["$","meta","16",{"name":"next-size-adjust"}]]
1:null
